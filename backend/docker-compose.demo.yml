version: '3.8'

services:
  token-optimizer:
    environment:
      # Demo: force aggressive input shrinking so token savings are obvious.
      # Use explicit values (not ${VAR:-default}) so this file is not affected by a
      # repo/root .env or shell-exported variables.
      MAX_INPUT_TOKENS: "2000"
      KEEP_LAST_N_TURNS: "1"
      SAFETY_MARGIN_TOKENS: "200"

      # Ensure tool schemas get minimized (big win for function/tool heavy prompts).
      # These are optimizer config keys (merged in app/main.py).
      # Pass per-request overrides if you need allowlist control.

      # Demo: enable semantic selection if you have sentence-transformers installed.
      # If not installed, it gracefully no-ops.
      SEMANTIC__ENABLED: "true"
      SEMANTIC__EMBEDDING_MODEL: "BAAI/bge-small-en-v1.5"
      SEMANTIC__VECTOR_TOPK: "12"
      SEMANTIC__MMR_LAMBDA: "0.6"
      SEMANTIC__BATCH_SIZE: "64"

      # Demo: aggressive compression.
      # If LLMLingua is not installed, it falls back to extractive summarization.
      COMPRESSION__ENABLED: "true"
      # Aggressive: compress must_keep blocks too (system/constraint are still protected).
      COMPRESSION__ALLOW_MUST_KEEP: "true"
      COMPRESSION__COMPRESSION_RATIO: "0.35"
      COMPRESSION__FAITHFULNESS_THRESHOLD: "0.75"
